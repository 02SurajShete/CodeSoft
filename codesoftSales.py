# -*- coding: utf-8 -*-
"""CodeSoftMovies.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sz9tzusRWvsvhc2F4xrVMwPLEt1aqp3C
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
# %matplotlib inline

path="/content/sample_data/advertising.csv"
movies=pd.read_csv(path)
movies.head()

movies.info

print("Rows", movies.shape[0])
print("Columns", movies.shape[1])

movies.dtypes

movies.isna().sum()

# Remove rows with any null values
movies = movies.dropna()
print(movies)

movies.isna().sum()

"""**Understanding the central tendencies**"""

print("Maximun Sales=",movies["Sales"].max())
print("Minimun Sales=",movies["Sales"].min())

#Standard Deviation of sales column
print("Standard Deviation", movies["Sales"].std())
#here the spread of the data is large due to SD>Mean

#Statistical Summary through table using aggrigate function
print("For TV")
movies.agg(
    {
    "Sales":["min", "max","mean"],
    "TV":["min", "max","mean"]
    }
)

print("For Radio")
movies.agg(
    {
    "Sales":["min", "max","mean"],
    "Radio":["min", "max","mean"]
    }
)

print("For Newspaper")
movies.agg(
    {
    "Sales":["min", "max","mean"],
    "Newspaper":["min", "max","mean"]
    }
)

"""**Finding Correlation**"""

movies.corr() #using corr() function

"""**Kurtosis**"""

#Kurtosis
movies.kurt()

"""**Skewness**"""

#Skewness
movies.skew()

movies.describe()

#walmart.describe(include="O")

"""**DATA VISUALIZATION:**



"""

movies.columns

"""HISTOGRAM PLOT:"""

bin=[0,2,4,6,8,10,12,14,16]
sns.histplot(x='Sales', bins=bin, data=movies, color="yellow", alpha=0.5)
plt.title("quantity and its count")
#this histogram show the quantity and its count

"""**Corr-relation matrix**"""

sns.heatmap(movies.corr(), annot=True, cmap="Blues")

"""**Linear Regression Model**

"""

x = movies.iloc[:, :-1].values
x

y = movies.iloc[:, 3].values
y

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=30)

x_train.size

lr = LinearRegression()
lr.fit(x_train, y_train)
y_predict = lr.predict(x_test)

#taking random values for prediction
y_pred= lr.predict([[45.6,55.2,42.1]])

print("Predicted Sales:",y_pred) #predicting Sales

r2_score = lr.score(x_train, y_train)
print("Training Score:", r2_score*100, "%")

r2_score = lr.score(x_test, y_test)
print("Testing Score:", r2_score*100, "%")

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Assuming y_true contains the actual sales
y_true = movies['Sales']

# Make predictions and assume y_pred contains the predicted sales
y_pred = lr.predict(x)

# Calculate evaluation metrics
mae = mean_absolute_error(y_true, y_pred)
mse = mean_squared_error(y_true, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_true, y_pred)

print(f"Mean Absolute Error (MAE): {mae}")
print(f"Mean Squared Error (MSE): {mse}")
print(f"Root Mean Squared Error (RMSE): {rmse}")
print(f"R-squared (R2): {r2}")

"""**-----END OF THE ANALYSIS------**"""